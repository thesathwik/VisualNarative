{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ada97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "\n",
    "def get_preprocessed_caption(caption):\n",
    "    caption = re.sub(r'\\s+', ' ', caption)\n",
    "    caption = caption.strip()\n",
    "    caption = \"<start> \" + caption + \" <end>\"\n",
    "    return caption\n",
    "\n",
    "def read_captions(dataset_path):\n",
    "    images_captions_dict = {}\n",
    "    with open(dataset_path + \"/captions.txt\", \"r\") as dataset_info:\n",
    "        next(dataset_info)\n",
    "        for info_raw in list(dataset_info)[:4000]:\n",
    "            info = info_raw.split(\",\")\n",
    "            image_filename = info[0]\n",
    "            caption = get_preprocessed_caption(info[1])\n",
    "            if image_filename not in images_captions_dict:\n",
    "                images_captions_dict[image_filename] = [caption]\n",
    "            else:\n",
    "                images_captions_dict[image_filename].append(caption)\n",
    "    return images_captions_dict\n",
    "\n",
    "def extract_image_features(images_captions_dict):\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(list(images_captions_dict.keys()))\n",
    "    image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(64)\n",
    "\n",
    "    images_dict = {}\n",
    "    encoder = get_encoder()\n",
    "    for img_tensor, path_tensor in tqdm(image_dataset):\n",
    "        batch_features_tensor = encoder(img_tensor)\n",
    "        for batch_features, path in zip(batch_features_tensor, path_tensor):\n",
    "            decoded_path = path.numpy().decode(\"utf-8\")\n",
    "            images_dict[decoded_path] = batch_features.numpy()\n",
    "    return images_dict\n",
    "\n",
    "def get_images_labels(image_filenames, images_dict, images_captions_dict):\n",
    "    images, labels = [], []\n",
    "    for image_filename in image_filenames:\n",
    "        image = images_dict[image_filename]\n",
    "        captions = images_captions_dict[image_filename]\n",
    "        for caption in captions:\n",
    "            images.append(image)\n",
    "            labels.append(caption)\n",
    "    return images, labels\n",
    "\n",
    "def create_tokenizer(captions):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=config.top_k, oov_token=\"<unk>\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "    tokenizer.fit_on_texts(captions)\n",
    "    tokenizer.word_index['<pad>'] = 0\n",
    "    tokenizer.index_word[0] = '<pad>'\n",
    "    return tokenizer\n",
    "\n",
    "def tokenize_captions(tokenizer, captions):\n",
    "    sequences = tokenizer.texts_to_sequences(captions)\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
    "\n",
    "def loss_function(real, pred, loss_object):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def clean_caption(caption):\n",
    "    return [item for item in caption if item not in ['<start>', '<end>', '<pad>']]\n",
    "\n",
    "def get_caption(img, encoder, decoder):\n",
    "    features = encoder(tf.expand_dims(img, 0))\n",
    "    caption = []\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    state = None\n",
    "\n",
    "    for i in range(config.max_caption_length):\n",
    "        predictions, memory_state, carry_state = decoder(dec_input, features, omit_features=i > 0, initial_state=state)\n",
    "        word_index = np.argmax(predictions.numpy().flatten())\n",
    "        if tokenizer.index_word[word_index] == '<end>':\n",
    "            break\n",
    "        caption.append(tokenizer.index_word[word_index])\n",
    "        dec_input = tf.expand_dims([word_index], 0)\n",
    "        state = [memory_state, carry_state]\n",
    "\n",
    "    return clean_caption(caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
